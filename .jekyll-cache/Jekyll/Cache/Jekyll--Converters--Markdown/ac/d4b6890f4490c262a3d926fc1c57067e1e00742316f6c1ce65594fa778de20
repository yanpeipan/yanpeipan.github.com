I"í,
<h1 id="å¹³å‡è´Ÿè½½load-averageçš„å®šä¹‰">å¹³å‡è´Ÿè½½(Load Average)çš„å®šä¹‰</h1>

<h2 id="cpuå¹³å‡è´Ÿè½½">CPUå¹³å‡è´Ÿè½½</h2>

<p>RFC 546 (1973)</p>

<blockquote>
  <p>[1] The TENEX load average is a measure of CPU demand.  The load
   average is an average of the number of runable processes over a given
   time period.  For example, an hourly load average of 10 would mean
   that (for a single CPU system) at any time during that hour one could
   expect to see 1 process running and 9 others ready to run (i.e., not
   blocked for I/O) waiting for the CPU.</p>
</blockquote>

<blockquote>
  <p>TENEX load averagesæ˜¯è¡¡é‡CPUéœ€æ±‚çš„æŒ‡æ ‡ã€‚è¿™ä¸ªå€¼æ˜¯ç»™å®šæ—¶é—´å†…å¯è¿è¡Œè¿›ç¨‹æ•°é‡çš„å¹³å‡å€¼ã€‚ä¾‹å¦‚ï¼Œå¯¹äºå•æ ¸CPUç³»ç»Ÿï¼Œæ¯å°æ—¶å¹³å‡10æ¬¡æ„æ€æ˜¯åœ¨è¯¥å°æ—¶å†…å¯ä»¥æœŸæœ›çœ‹åˆ°ä¸€ä¸ªè¿›ç¨‹æ­£åœ¨è¿è¡Œå’Œå¦å¤–ä¹ä¸ªç­‰å¾…CPU(å³æ²¡æœ‰è¢«I/Oé˜»å¡)å¤„äºreadyçŠ¶æ€çš„è¿›ç¨‹ã€‚</p>
</blockquote>

<h2 id="ä¸å¯ä¸­æ–­ä»»åŠ¡">ä¸å¯ä¸­æ–­ä»»åŠ¡</h2>

<p><a href="http://oldlinux.org/Linux.old/mail-archive/">oldlinux.org</a> ä¸Š1993å¹´çš„ä¸€å°é‚®ä»¶:</p>
<blockquote>

  <p>From: Matthias Urlichs <a href="mailto:urlichs@smurf.sub.org">urlichs@smurf.sub.org</a><br />
Subject: Load average broken ?<br />
Date: Fri, 29 Oct 1993 11:37:23 +0200</p>

  <p>The kernel only counts â€œrunnableâ€ processes when computing the load average.
I donâ€™t like that; the problem is that processes which are swapping or
waiting on â€œfastâ€, i.e. noninterruptible, I/O, also consume resources.<br />
It seems somewhat nonintuitive that the load average goes down when you
replace your fast swap disk with a slow swap diskâ€¦<br />
Anyway, the following patch seems to make the load average much more
consistent WRT the subjective speed of the system. And, most important, the
load is still zero when nobody is doing anything. ;-)</p>
</blockquote>

<p>ç»å¤§å¤šæ•°ç±» Unix ç³»ç»Ÿåªç»Ÿè®¡è¿è¡Œå’Œç­‰å¾…çŠ¶æ€çš„è¿›ç¨‹ã€‚ä½†æ˜¯åœ¨ Linux ä¸­ï¼Œå¹³å‡è´Ÿè½½ä¹ŸåŒ…æ‹¬å¤„äºä¸å¯æ‰“æ–­çš„ç¡çœ çŠ¶æ€çš„è¿›ç¨‹ï¼ˆTASK_UNINTERRUPTIBLEæˆ–nr_uninterruptibleï¼‰â€”â€”è¿™ç§çŠ¶æ€ç”±å¸Œæœ›é¿å…ä¿¡å·ä¸­æ–­çš„ä»£ç ä½¿ç”¨ï¼Œå…¶ä¸­åŒ…æ‹¬é˜»å¡åœ¨ç£ç›˜I/Oå’Œä¸€äº›é”ä¸Šçš„ä»»åŠ¡ã€‚</p>

<p>ä½¿ç”¨<code>man ps</code> (process status)æŸ¥çœ‹ï¼š</p>
<blockquote>
  <p>ps displays information about a selection of the active processes.  If you want a repetitive update of the selection and the displayed information, use top(1) instead.</p>
</blockquote>

<blockquote>
  <p>Here are the different values that the s, stat and state output specifiers (header â€œSTATâ€ or â€œSâ€) will display to describe the state of a process:</p>
  <blockquote>
    <p>D    uninterruptible sleep (usually IO)  <br />
R    running or runnable (on run queue)<br />
S    interruptible sleep (waiting for an event to complete)<br />
T    stopped by job control signal<br />
t    stopped by debugger during the tracing<br />
W    paging (not valid since the 2.6.xx kernel)<br />
X    dead (should never be seen)<br />
Z    defunct (â€œzombieâ€) process, terminated but not reaped by its parent</p>
  </blockquote>
</blockquote>

<p>æ³¨ï¼šå‚è§ã€ŠOPERATING SYSTEMã€‹  A process is an â€˜activeâ€™ entity as opposed to program which is considered to be a â€˜passiveâ€™ entity. è¿›ç¨‹æ˜¯æ´»è·ƒçš„ï¼Œä¸ä¹‹ç›¸åç¨‹åºï¼ˆä»£ç ï¼‰æ˜¯ä¸æ´»è·ƒçš„ã€‚æ‰€ä»¥active processesæ´»è·ƒè¿›ç¨‹åŒ…å«æ‰€æœ‰çŠ¶æ€çš„è¿›ç¨‹ã€‚</p>

<h2 id="ç³»ç»Ÿå¹³å‡è´Ÿè½½">ç³»ç»Ÿå¹³å‡è´Ÿè½½</h2>

<p>ä½¿ç”¨<code>man uptime</code>å‘½ä»¤æ¥äº†è§£å¹³å‡è´Ÿè½½çš„è¯¦ç»†è§£é‡Šã€‚</p>

<blockquote>

  <p>System  load  averages  is the average number of processes that are either in a runnable or uninterruptable state.  A process in a runnable state is either using the CPU or waiting to use the CPU.  A process in uninterruptable state is waiting for some I/O access, eg waiting for disk.  The averages are taken over the three time intervals.  Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a  4  CPU  system  it means it was idle 75% of the time.</p>

  <p>ç³»ç»Ÿè´Ÿè½½å¹³å‡æ˜¯å¤„äºå¯è¿è¡Œæˆ–ä¸å¯ä¸­æ–­çŠ¶æ€çš„è¿›ç¨‹çš„å¹³å‡æ•°é‡ã€‚å¤„äºå¯è¿è¡ŒçŠ¶æ€çš„è¿›ç¨‹è¦ä¹ˆä½¿ç”¨CPUï¼Œè¦ä¹ˆç­‰å¾…ä½¿ç”¨CPUã€‚å¤„äºä¸å¯ä¸­æ–­çŠ¶æ€çš„è¿›ç¨‹æ­£åœ¨ç­‰å¾…ä¸€äº›I/Oè®¿é—®(å¦‚ç­‰å¾…ç£ç›˜)ã€‚å¹³å‡å€¼åœ¨ä¸‰ä¸ªæ—¶é—´é—´éš”å†…å–ã€‚å¯¹äºç³»ç»Ÿä¸­çš„CPUæ•°é‡ï¼Œè´Ÿè½½å¹³å‡å¹¶ä¸æ˜¯æ ‡å‡†åŒ–çš„ï¼Œæ‰€ä»¥è´Ÿè½½å¹³å‡ä¸º1æ„å‘³ç€ä¸€ä¸ªCPUç³»ç»Ÿä¸€ç›´åœ¨åŠ è½½ï¼Œè€Œå¯¹äº4 CPUç³»ç»Ÿï¼Œè´Ÿè½½å¹³å‡ä¸º75%çš„æ—¶é—´æ˜¯ç©ºé—²çš„ã€‚</p>
</blockquote>

<p>é™¤æ­¤ä¹‹å¤–è¿˜å¯ä½¿ç”¨ <code>w</code> <code>top</code>, åŠå„ç§å¢å¼ºç‰ˆ<code>atop</code> <code>htop</code> <code>glances</code>ç­‰ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨<code>cat /proc/loadavg</code>å‘½ä»¤è¯»å–ã€‚</p>

<h2 id="å®ç°">å®ç°</h2>

<p>linux/fs/proc/loadavg.c</p>
<pre><code>static int loadavg_proc_show(struct seq_file *m, void *v)
{
	unsigned long avnrun[3];

	get_avenrun(avnrun, FIXED_1/200, 0);

	seq_printf(m, "%lu.%02lu %lu.%02lu %lu.%02lu %ld/%d %d\n",
		LOAD_INT(avnrun[0]), LOAD_FRAC(avnrun[0]),
		LOAD_INT(avnrun[1]), LOAD_FRAC(avnrun[1]),
		LOAD_INT(avnrun[2]), LOAD_FRAC(avnrun[2]),
		nr_running(), nr_threads,
		idr_get_cursor(&amp;task_active_pid_ns(current)-&gt;idr) - 1);
	return 0;
}
</code></pre>

<p>linux/include/linux/sched/loadavg.h</p>
<pre><code>#define EXP_1		1884		/* 1/exp(5sec/1min) as fixed-point */
#define EXP_5		2014		/* 1/exp(5sec/5min) */
#define EXP_15		2037		/* 1/exp(5sec/15min) */

/*
 * a1 = a0 * e + a * (1 - e)
 */
static inline unsigned long
calc_load(unsigned long load, unsigned long exp, unsigned long active)
{
	unsigned long newload;

	newload = load * exp + active * (FIXED_1 - exp);
	if (active &gt;= load)
		newload += FIXED_1-1;

	return newload / FIXED_1;
}
</code></pre>

<p>linux/kernel/sched/loadavg.c</p>
<pre><code>
/*
 * Global load-average calculations
 *
 * We take a distributed and async approach to calculating the global load-avg
 * in order to minimize overhead.
 *
 * The global load average is an exponentially decaying average of nr_running +
 * nr_uninterruptible.
 *
 * Once every LOAD_FREQ:
 *
 *   nr_active = 0;
 *   for_each_possible_cpu(cpu)
 *	nr_active += cpu_of(cpu)-&gt;nr_running + cpu_of(cpu)-&gt;nr_uninterruptible;
 *
 *   avenrun[n] = avenrun[0] * exp_n + nr_active * (1 - exp_n)
...
*/

/*
 * calc_load - update the avenrun load estimates 10 ticks after the
 * CPUs have updated calc_load_tasks.
 *
 * Called from the global timer code.
 */
void calc_global_load(unsigned long ticks)
{
	unsigned long sample_window;
	long active, delta;

	sample_window = READ_ONCE(calc_load_update);
	if (time_before(jiffies, sample_window + 10))
		return;

	/*
	 * Fold the 'old' NO_HZ-delta to include all NO_HZ CPUs.
	 */
	delta = calc_load_nohz_fold();
	if (delta)
		atomic_long_add(delta, &amp;calc_load_tasks);

	active = atomic_long_read(&amp;calc_load_tasks);
	active = active &gt; 0 ? active * FIXED_1 : 0;

	avenrun[0] = calc_load(avenrun[0], EXP_1, active);
	avenrun[1] = calc_load(avenrun[1], EXP_5, active);
	avenrun[2] = calc_load(avenrun[2], EXP_15, active);

	WRITE_ONCE(calc_load_update, sample_window + LOAD_FREQ);

	/*
	 * In case we went to NO_HZ for multiple LOAD_FREQ intervals
	 * catch up in bulk.
	 */
	calc_global_nohz();
}
</code></pre>
<p>ä¸ºäº†æœ€å°åŒ–å¼€é”€ï¼ŒLinuxé‡‡ç”¨åˆ†å¸ƒå¼å’Œå¼‚æ­¥çš„æ–¹æ³•æ¥è®¡ç®—å…¨å±€è´Ÿè½½å¹³å‡åˆ†é…ã€‚å…¨å±€è´Ÿè½½å¹³å‡å€¼æ˜¯nr_running + nr_uninterruptibleçš„æŒ‡æ•°è¡°å‡å¹³å‡å€¼ã€‚<br />
Linuxå†…æ ¸å®šä¹‰ä¸€ä¸ªé•¿åº¦ä¸º3çš„åŒå­—æ•°ç»„avenrunï¼ŒåŒå­—çš„ä½11ä½ç”¨äºå­˜æ”¾è´Ÿè½½çš„å°æ•°éƒ¨åˆ†ï¼Œé«˜21ä½ç”¨äºå­˜æ”¾æ•´æ•°éƒ¨åˆ†ã€‚</p>

<blockquote>

  <p>æ³¨ï¼šlinux kernelçš„è®¾è®¡å“²å­¦æ˜¯ç¦æ­¢åœ¨å†…æ ¸é‡Œä½¿ç”¨æµ®ç‚¹æ“ä½œçš„ï¼Œè¿™æ˜¯ä»æ€§èƒ½ä¸Šçš„è€ƒè™‘ï¼Œå› ä¸ºè¿™æ ·åšå¯ä»¥çœå»åœ¨ç”¨æˆ·æ€ä¸å†…æ ¸æ€ä¹‹é—´è¿›è¡Œåˆ‡æ¢æ—¶ä¿å­˜/æ¢å¤æµ®ç‚¹å¯„å­˜å™¨ FPUçš„æ“ä½œ, å†…æ ¸æµ®ç‚¹è®¡ç®—ä»£ç å—ä¸­ï¼Œå¿…é¡»ä½¿ç”¨ <code>kernel_fpu_begin()</code>å’Œ<code>kernel_fpu_end()</code>è¿™ä¸¤ä¸ªå‡½æ•°åŒ…èµ·æ¥ã€‚è¿™ä¸¤ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯è®©å†…æ ¸æ„ŸçŸ¥ä¸åˆ°OSè¿è¡Œè¿‡ç¨‹ä¸­æœ‰ä½¿ç”¨ç¡¬ä»¶æµ®ç‚¹å¯„å­˜å™¨   <br />
æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆè‹±è¯­ï¼šexponential moving averageï¼ŒEMAæˆ–EXMAï¼‰æ˜¯ä»¥æŒ‡æ•°å¼é€’å‡åŠ æƒçš„ç§»åŠ¨å¹³å‡ã€‚å„æ•°å€¼çš„åŠ æƒå½±å“åŠ›éšæ—¶é—´è€ŒæŒ‡æ•°å¼é€’å‡ï¼Œè¶Šè¿‘æœŸçš„æ•°æ®åŠ æƒå½±å“åŠ›è¶Šé‡ï¼Œä½†è¾ƒæ—§çš„æ•°æ®ä¹Ÿç»™äºˆä¸€å®šçš„åŠ æƒå€¼</p>
</blockquote>

<h1 id="æŒ‡æ ‡çš„ä¸‰ä¸ªç²’åº¦">æŒ‡æ ‡çš„ä¸‰ä¸ªç²’åº¦</h1>

<h2 id="ç†è§£linuxçš„å¹³å‡è´Ÿè½½">ç†è§£Linuxçš„å¹³å‡è´Ÿè½½</h2>
<pre><code>uptime
13:17  up 23:48, 5 users, load averages: 2.31 2.44 2.46
</code></pre>
<ul>
  <li>å¦‚æœå¹³å‡å€¼æ˜¯0.0ï¼Œè¯´æ˜ç³»ç»Ÿå¤„äºç©ºé—²çŠ¶æ€</li>
  <li>å¦‚æœ1åˆ†é’Ÿçš„å¹³å‡å€¼å¤§äº5åˆ†é’Ÿæˆ–è€…15åˆ†é’Ÿï¼Œè¯´æ˜ç³»ç»Ÿè´Ÿè½½æ­£åœ¨å¢åŠ </li>
  <li>å¦‚æœ1åˆ†é’Ÿçš„å¹³å‡å€¼å°äº5åˆ†é’Ÿæˆ–è€…15åˆ†é’Ÿï¼Œè¯´æ˜ç³»ç»Ÿè´Ÿè½½æ­£åœ¨å‡å°</li>
  <li>å¦‚æœè¿™äº›å€¼å¤§äºCPUçš„ä¸ªæ•°ï¼Œè¯´æ˜å¯èƒ½é‡åˆ°äº†æ€§èƒ½é—®é¢˜</li>
  <li>ç³»ç»Ÿå¹³å‡è´Ÿè½½æ¶‰åŠä¸åŒçš„èµ„æºç±»å‹ï¼Œå› æ­¤å®ƒä»¬æ›´åŠ æ¨¡ç³Šï¼Œæ‰€ä»¥ä¸èƒ½åªé™¤ä»¥CPUè®¡æ•°</li>
</ul>

<p>æ³¨ï¼šæŸ¥çœ‹CPUä¸ªæ•° <code>grep 'model name' /proc/cpuinfo | wc -l</code> )</p>

<h2 id="æ¨¡æ‹Ÿåˆ†æ">æ¨¡æ‹Ÿåˆ†æ</h2>

<pre><code>apt install sysstat
</code></pre>

<h3 id="cpuå¯†é›†">CPUå¯†é›†</h3>

<pre><code>stress -i 1 --timeout 600

watch -d uptime

Every 2.0s: uptime                                                                                                                                                          2018: Wed Dec 19 20:05:44 2018

 20:05:44 up  6:30,  3 users,  load average: 0.57, 0.37, 0.21

mpstat -P ALL 5

20æ—¶05åˆ†11ç§’  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
20æ—¶05åˆ†16ç§’  all   12.60    0.00    0.05    0.00    0.00    0.00    0.00    0.00    0.00   87.35
20æ—¶05åˆ†16ç§’    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
20æ—¶05åˆ†16ç§’    1    0.60    0.00    0.20    0.20    0.00    0.00    0.00    0.00    0.00   99.00
20æ—¶05åˆ†16ç§’    2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
20æ—¶05åˆ†16ç§’    3    0.00    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   99.80
20æ—¶05åˆ†16ç§’    4    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
20æ—¶05åˆ†16ç§’    5    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
20æ—¶05åˆ†16ç§’    6  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
20æ—¶05åˆ†16ç§’    7    0.20    0.00    0.20    0.00    0.00    0.00    0.00    0.00    0.00   99.60
</code></pre>

<h3 id="ioå¯†é›†">IOå¯†é›†</h3>

<pre><code>stress -d 1 --hdd-bytes 1G -t 600

stress-ng -i 1 --hdd 1 --timeout 600

watch -d uptime

mpstat -P ALL 5

pidstat -u 5
</code></pre>

<h3 id="è¿›ç¨‹ç«äº‰">è¿›ç¨‹ç«äº‰</h3>

<pre><code>stress -c 8 --timeout 600

watch -d vmstat
</code></pre>

<hr />
<ul>
  <li><a href="https://juejin.im/post/5b18d47ce51d4506c3354d54">æ·±å…¥ç†è§£load averages</a></li>
  <li><a href="http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html">Linux Load Averages: Solving the Mystery</a></li>
  <li><a href="https://time.geekbang.org/column/article/69618">åŸºç¡€ç¯‡ï¼šåˆ°åº•åº”è¯¥æ€ä¹ˆç†è§£â€œå¹³å‡è´Ÿè½½â€ï¼Ÿ</a></li>
  <li><a href="https://www.studytonight.com/operating-system/operating-system-processes">What is a Process?</a></li>
</ul>
:ET